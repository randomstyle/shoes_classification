{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning using MNIST data\n",
    "To illustrate the power and concept of transfer learning, we will train a CNN on just the digits 5,6,7,8,9.  Then we will train just the last layer(s) of the network on the digits 0,1,2,3,4 and see how well the features learned on 5-9 help with classifying 0-4.\n",
    "\n",
    "Adapted from https://github.com/fchollet/keras/blob/master/examples/mnist_transfer_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/huynh/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow\n",
    "import datetime\n",
    "import keras\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from PIL import Image\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_paths(path, im):\n",
    "    listing = os.listdir(path)\n",
    "    count = 0\n",
    "    for item in listing:\n",
    "\n",
    "        if item == '.DS_Store':\n",
    "            continue\n",
    "        else:\n",
    "            if '.jpg' in listing[0]:\n",
    "                if count == 0:\n",
    "                    im += [path + '/' + i for i in listing]\n",
    "                    count += 1\n",
    "            else:         \n",
    "                get_image_paths(path + '/' + item, im)\n",
    "\n",
    "# path to the images folder download from the website\n",
    "dir_path = \"/Users/huynh/Desktop/256/ut-zap50k-images\"\n",
    "# path to store new resized images\n",
    "resize_path = '/Users/huynh/AnacondaProjects/256Project/resize_img'\n",
    "im = []\n",
    "get_image_paths(dir_path, im)\n",
    "\n",
    "fp = open('combine_data.csv', 'w') \n",
    "for path in im:\n",
    "    if path.split('/')[6] == 'Boots':\n",
    "        fp.write(path + ',0\\n')\n",
    "    elif path.split('/')[6] == 'Sandals':\n",
    "        fp.write(path + ',1\\n')\n",
    "    elif path.split('/')[6] == 'Shoes':\n",
    "        fp.write(path + ',2\\n')\n",
    "    elif path.split('/')[6] == 'Slippers':\n",
    "        fp.write(path + ',3\\n')\n",
    "fp.close()\n",
    "#used to help some of the timing functions\n",
    "now = datetime.datetime.now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set some parameters\n",
    "batch_size = 300\n",
    "num_classes = 4\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set some more parameters\n",
    "img_rows, img_cols = 50, 50\n",
    "filters = 32\n",
    "pool_size = 2\n",
    "kernel_size = 5\n",
    "img_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imlist=[]\n",
    "label = []\n",
    "count = 0\n",
    "with open('combine_data.csv') as f:\n",
    "    for line in f:\n",
    "        arr = line.split(',')\n",
    "        imlist.append(arr[0])\n",
    "        label.append(arr[1])\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create matrix to store all flattened images\n",
    "c1 = 0\n",
    "\n",
    "for path in imlist:\n",
    "    temp = Image.open(path)\n",
    "    temp = temp.resize((img_rows,img_cols))\n",
    "    temp = temp.convert('L')\n",
    "    temp.save(resize_path + '/' + label[c1][0:1] + '_' + str(c1) + '.jpg', \"JPEG\")\n",
    "    c1 += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50025\n",
      "[[255 255 255 ..., 255 255 255]\n",
      " [255 255 255 ..., 255 255 255]\n",
      " [255 255 255 ..., 255 255 255]\n",
      " ..., \n",
      " [255 255 255 ..., 255 255 255]\n",
      " [255 255 255 ..., 255 255 255]\n",
      " [255 255 255 ..., 255 255 255]]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(resize_path):\n",
    "    os.makedirs(resize_path)\n",
    "    \n",
    "imlist1 = os.listdir(resize_path)\n",
    "immatrix = np.array([np.array(Image.open(resize_path + '/' + im2)).flatten() for im2 in imlist1])\n",
    "immatrix.astype(float)\n",
    "print(len(immatrix))\n",
    "print(immatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = np.ones((50025,),dtype = int)\n",
    "c2 = 0\n",
    "for item in imlist1:\n",
    "    label1[c2] = item.split('_')[0]\n",
    "    c2 += 1\n",
    "\n",
    "\n",
    "data,Label = shuffle(immatrix,label1, random_state=2)\n",
    "train_data = [data,Label]\n",
    "\n",
    "(x, y) = (train_data[0], train_data[1])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## To simplify things, write a function to include all the training steps\n",
    "## As input, function takes a model, training set, test set, and the number of classes\n",
    "## Inside the model object will be the state about which layers we are freezing and which we are training\n",
    "\n",
    "def train_model(model, x_train, x_test, y_train, y_test, num_classes):\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols,1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols,1)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    t = now()\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=1,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    print('Training time: %s' % (now() - t))\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the \"feature\" layers.  These are the early layers that we expect will \"transfer\"\n",
    "# to a new problem.  We will freeze these layers during the fine-tuning process\n",
    "\n",
    "feature_layers = [\n",
    "    Conv2D(filters, kernel_size,\n",
    "           padding='valid',\n",
    "           input_shape=(img_rows, img_cols,1)),\n",
    "    Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the \"classification\" layers.  These are the later layers that predict the specific classes from the features\n",
    "# learned by the feature layers.  This is the part of the model that needs to be re-trained for a new problem\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create our model by combining the two sets of layers as follows\n",
    "model = Sequential(feature_layers + classification_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 32)        832       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 46, 46, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 42, 42, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 42, 42, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 14112)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1806464   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,833,444\n",
      "Trainable params: 1,833,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (40020, 50, 50, 1)\n",
      "40020 train samples\n",
      "10005 test samples\n",
      "Train on 40020 samples, validate on 10005 samples\n",
      "Epoch 1/1\n",
      "40020/40020 [==============================] - 657s - loss: 0.5765 - acc: 0.8021 - val_loss: 0.3664 - val_acc: 0.8760\n",
      "Training time: 0:10:57.912123\n",
      "Test score: 0.366437373588\n",
      "Test accuracy: 0.875962018996\n"
     ]
    }
   ],
   "source": [
    "# Now, let's train our model on the digits 5,6,7,8,9\n",
    "\n",
    "train_model(model, x_train, x_test, y_train, y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
