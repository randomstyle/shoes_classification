{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning using MNIST data\n",
    "To illustrate the power and concept of transfer learning, we will train a CNN on just the digits 5,6,7,8,9.  Then we will train just the last layer(s) of the network on the digits 0,1,2,3,4 and see how well the features learned on 5-9 help with classifying 0-4.\n",
    "\n",
    "Adapted from https://github.com/fchollet/keras/blob/master/examples/mnist_transfer_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/u6975/.conda/envs/tensorflow-36/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow\n",
    "import datetime\n",
    "import keras\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from PIL import Image\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################## set up some variables #################\n",
    "#dir_path = \"/Users/huynh/Desktop/256/ut-zap50k-images\"\n",
    "#resize_path = 'resize_img'\n",
    "im = []\n",
    "\n",
    "# set some parameters\n",
    "batch_size = 300\n",
    "num_classes = 7\n",
    "epochs = 5\n",
    "\n",
    "# set some more parameters\n",
    "img_rows, img_cols = 50, 50\n",
    "filters = 32\n",
    "pool_size = 2\n",
    "kernel_size = 5\n",
    "img_channels = 1\n",
    "\n",
    "#used to help some of the timing functions\n",
    "now = datetime.datetime.now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the path to all pictures in im list. Comment out cuz we got it\n",
    "#def get_image_paths(path, im):\n",
    "#    listing = os.listdir(path)\n",
    "#    count = 0\n",
    "#    for item in listing:\n",
    "\n",
    "#        if item == '.DS_Store':\n",
    "#            continue\n",
    "#        else:\n",
    "#            if '.jpg' in listing[0]:\n",
    "#                if count == 0:\n",
    "#                    im += [path + '/' + i for i in listing]\n",
    "#                    count += 1\n",
    "#            else:         \n",
    "#                get_image_paths(path + '/' + item, im)\n",
    "\n",
    "#get_image_paths(dir_path, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create resize_images. Comment out because we got it\n",
    "#for path in imlist:\n",
    "#    temp = Image.open(path)\n",
    "#    temp = temp.resize((img_rows,img_cols))\n",
    "#    temp = temp.convert('L')\n",
    "#    fileName = path.split('/')[-1]\n",
    "#    tempArr = fileName.split('-')\n",
    "#    temp.save('/home/u6975/resize_img/' + tempArr[0] + '-' + tempArr[1], \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################ function to train the model ##################\n",
    "def train_model(model, x_train, x_test, y_train, y_test, num_classes, epochs, featureName):\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols,1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols,1)\n",
    "    \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    t = now()\n",
    "    # checkpoint\n",
    "    if featureName == 'Category':\n",
    "        filepath=\"/home/u6975/models/\" + featureName + \".best.hdf5\"\n",
    "    elif featureName == 'Gender':\n",
    "        filepath=\"/home/u6975/models/\" + featureName + \".best.hdf5\"\n",
    "    elif featureName == 'SubCategory':\n",
    "        filepath=\"/home/u6975/models/\" + featureName + \".best.hdf5\"\n",
    "    elif featureName == 'HeelHeight':\n",
    "        filepath=\"/home/u6975/models/\" + featureName + \".best.hdf5\"\n",
    "    elif featureName == 'Material':\n",
    "        filepath=\"/home/u6975/models/\" + featureName + \".best.hdf5\"\n",
    "        \n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              callbacks=callbacks_list,\n",
    "              verbose=0,\n",
    "              validation_data=(x_test, y_test))\n",
    "    #print('Training time: %s' % (now() - t))\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "    ################ feature reducing layer ##############\n",
    "    feature_layers = [\n",
    "        Conv2D(filters, kernel_size,\n",
    "               padding='valid',\n",
    "               input_shape=(img_rows, img_cols,1)),\n",
    "        Activation('relu'),\n",
    "        Conv2D(filters, kernel_size),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=pool_size),\n",
    "        Dropout(0.25),\n",
    "        Flatten(),\n",
    "    ]\n",
    "\n",
    "    ############ classification layer ############\n",
    "    classification_layers = [\n",
    "        Dense(128),\n",
    "        Activation('relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes),\n",
    "        Activation('softmax')\n",
    "    ]\n",
    "\n",
    "    # We create our model by combining the two sets of layers as follows\n",
    "    model = Sequential(feature_layers + classification_layers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################# Needed function ##############\n",
    "# filter df to the needed cols and modify the new df CID col\n",
    "def get_df(filterString):\n",
    "    df = pd.read_csv('meta-data-bin.csv')\n",
    "    df1 = df.filter(regex='CID').join(df.filter(regex=filterString))\n",
    "\n",
    "    for x in range(50025):\n",
    "        df1.iloc[[x],[0]] = '/home/u6975/resize_img/' + df1.iloc[[x],[0]] + '.jpg'\n",
    "    return df1\n",
    "\n",
    "# join table and drop NaN\n",
    "def join_drop(df, feature):\n",
    "    df1 = pd.read_csv('meta-data.csv')\n",
    "    df1 = df1.drop('CID', 1)\n",
    "    df2 = df1.join(df)\n",
    "    df2 = df2.dropna(subset=[feature])\n",
    "    df2 = df2.filter(regex='CID').join(df.filter(regex=feature))\n",
    "    df2 = df2[~df2['CID'].isin(['/home/u6975/resize_img/8029595-574.jpg'])]\n",
    "    return df2\n",
    "\n",
    "# make a matrix for flatten img\n",
    "def make_matrix(df):    \n",
    "    imlist1 = df['CID'].values.tolist()\n",
    "    immatrix = np.array([np.array(Image.open(im2)).flatten() for im2 in imlist1])\n",
    "    immatrix.astype(float)\n",
    "    return immatrix\n",
    "\n",
    "# make labels list\n",
    "def make_label(df):\n",
    "    temp = len(df.index)\n",
    "    label1 = np.ones((temp,),dtype = int)\n",
    "    for x in range(temp):\n",
    "        for t in range(df.shape[1]):\n",
    "            if df.get_value(x, t, takeable=True) == 1:\n",
    "                label1[x] = t - 1\n",
    "                break\n",
    "    return label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ This part is for Gender ###############\n",
    "# Men\n",
    "# Women\n",
    "# Boy\n",
    "# Girl\n",
    "\n",
    "# init some variables\n",
    "feature = 'Gender'\n",
    "num_classes = 4\n",
    "epochs = 5\n",
    "\n",
    "# prepare data from dataset\n",
    "df1 = get_df(feature)\n",
    "df1 = join_drop(df1, feature)\n",
    "\n",
    "# format them into expected data structure\n",
    "new_matrix = make_matrix(df1)\n",
    "new_label = make_label(df1)\n",
    "new_model = get_model(num_classes)\n",
    "\n",
    "# prepare data for training\n",
    "data,Label = shuffle(new_matrix, new_label, random_state=2)\n",
    "train_data = [data,Label]\n",
    "(x, y) = (train_data[0], train_data[1])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 46, 46, 32)        832       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 46, 46, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 42, 42, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 42, 42, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 14112)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               1806464   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,833,444\n",
      "Trainable params: 1,833,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "x_train shape: (40014, 50, 50, 1)\n",
      "40014 train samples\n",
      "10004 test samples\n",
      "Epoch 00000: val_acc improved from -inf to 0.62975, saving model to /home/u6975/models/Gender.best.hdf5\n",
      "Epoch 00001: val_acc improved from 0.62975 to 0.67543, saving model to /home/u6975/models/Gender.best.hdf5\n",
      "Epoch 00002: val_acc improved from 0.67543 to 0.67593, saving model to /home/u6975/models/Gender.best.hdf5\n",
      "Epoch 00003: val_acc improved from 0.67593 to 0.71441, saving model to /home/u6975/models/Gender.best.hdf5\n",
      "Epoch 00004: val_acc improved from 0.71441 to 0.71631, saving model to /home/u6975/models/Gender.best.hdf5\n",
      "Test score: 0.699081667206\n",
      "Test accuracy: 0.716313474634\n"
     ]
    }
   ],
   "source": [
    "# train it\n",
    "train_model(new_model, x_train, x_test, y_train, y_test, num_classes, epochs, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ This part is for SubCategory ###############\n",
    "# Oxfords\n",
    "# Mid.Calf\n",
    "# Heel\n",
    "# Ankle\n",
    "# Boot\n",
    "# Loafers\n",
    "# Slipper.Flats\n",
    "# Boat.Shoes\n",
    "# Flat\n",
    "# Clogs.and.Mules\n",
    "# Flats\n",
    "# Sneakers.and.Athletic.Shoes\n",
    "# Slipper.Heels\n",
    "# Heels\n",
    "# Athletic\n",
    "# Prewalker\n",
    "# Knee.High\n",
    "# Prewalker.Boots\n",
    "# Crib.Shoes\n",
    "# Firstwalker\n",
    "# Over.the.Knee\n",
    "\n",
    "# init some variables\n",
    "feature = 'SubCategory'\n",
    "num_classes = 21\n",
    "epochs = 5\n",
    "\n",
    "# prepare data from dataset\n",
    "df1 = get_df(feature)\n",
    "df1 = join_drop(df1, feature)\n",
    "\n",
    "# format them into expected data structure\n",
    "new_matrix = make_matrix(df1)\n",
    "new_label = make_label(df1)\n",
    "new_model = get_model(num_classes)\n",
    "\n",
    "# prepare data for training\n",
    "data,Label = shuffle(new_matrix, new_label, random_state=2)\n",
    "train_data = [data,Label]\n",
    "(x, y) = (train_data[0], train_data[1])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (40019, 50, 50, 1)\n",
      "40019 train samples\n",
      "10005 test samples\n",
      "Epoch 00000: val_acc improved from -inf to 0.69075, saving model to /home/u6975/models/SubCategory.best.hdf5\n",
      "Epoch 00001: val_acc improved from 0.69075 to 0.73023, saving model to /home/u6975/models/SubCategory.best.hdf5\n",
      "Epoch 00002: val_acc improved from 0.73023 to 0.74513, saving model to /home/u6975/models/SubCategory.best.hdf5\n",
      "Epoch 00003: val_acc improved from 0.74513 to 0.77491, saving model to /home/u6975/models/SubCategory.best.hdf5\n",
      "Epoch 00004: val_acc did not improve\n",
      "Test score: 0.684641489489\n",
      "Test accuracy: 0.771214392833\n"
     ]
    }
   ],
   "source": [
    "# train it\n",
    "train_model(new_model, x_train, x_test, y_train, y_test, num_classes, epochs, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 46, 46, 32)        832       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 46, 46, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 42, 42, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 42, 42, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 14112)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               1806464   \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 903       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 1,833,831\n",
      "Trainable params: 1,833,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "############ This part is for HeelHeight ###############\n",
    "# 1in...1.3.4in, \n",
    "# 2in...2.3.4in, \n",
    "# Under.1in,\n",
    "# Flat,\n",
    "# 4in...4.3.4in,\n",
    "# 3in...3.3.4in,\n",
    "# 5in...over\n",
    "\n",
    "# init some variables\n",
    "feature = 'HeelHeight'\n",
    "num_classes = 7\n",
    "epochs = 5\n",
    "\n",
    "# prepare data from dataset\n",
    "df1 = get_df(feature)\n",
    "df1 = join_drop(df1, feature)\n",
    "\n",
    "# format them into expected data structure\n",
    "new_matrix = make_matrix(df1)\n",
    "new_label = make_label(df1)\n",
    "new_model = get_model(num_classes)\n",
    "\n",
    "# prepare data for training\n",
    "data,Label = shuffle(new_matrix, new_label, random_state=2)\n",
    "train_data = [data,Label]\n",
    "(x, y) = (train_data[0], train_data[1])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (23974, 50, 50, 1)\n",
      "23974 train samples\n",
      "5994 test samples\n",
      "Epoch 00000: val_acc improved from -inf to 0.56156, saving model to /home/u6975/models/HeelHeight.best.hdf5\n",
      "Epoch 00001: val_acc improved from 0.56156 to 0.61228, saving model to /home/u6975/models/HeelHeight.best.hdf5\n",
      "Epoch 00002: val_acc improved from 0.61228 to 0.62029, saving model to /home/u6975/models/HeelHeight.best.hdf5\n",
      "Epoch 00003: val_acc improved from 0.62029 to 0.63697, saving model to /home/u6975/models/HeelHeight.best.hdf5\n",
      "Epoch 00004: val_acc improved from 0.63697 to 0.65616, saving model to /home/u6975/models/HeelHeight.best.hdf5\n",
      "Test score: 0.874347035154\n",
      "Test accuracy: 0.656156156176\n"
     ]
    }
   ],
   "source": [
    "# train it\n",
    "train_model(new_model, x_train, x_test, y_train, y_test, num_classes, epochs, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 32)        832       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 46, 46, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 42, 42, 32)        25632     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 42, 42, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 14112)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1806464   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 516       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 1,833,444\n",
      "Trainable params: 1,833,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "############ This part is for Category ###############\n",
    "# Shoes\n",
    "# Boots\n",
    "# Sandals\n",
    "# Slippers\n",
    "\n",
    "# init some variables\n",
    "feature = 'Category'\n",
    "num_classes = 4\n",
    "epochs = 5\n",
    "\n",
    "# prepare data from dataset\n",
    "df1 = get_df(feature)\n",
    "df1 = join_drop(df1, feature)\n",
    "\n",
    "# format them into expected data structure\n",
    "new_matrix = make_matrix(df1)\n",
    "new_label = make_label(df1)\n",
    "new_model = get_model(num_classes)\n",
    "\n",
    "# prepare data for training\n",
    "data,Label = shuffle(new_matrix, new_label, random_state=2)\n",
    "train_data = [data,Label]\n",
    "(x, y) = (train_data[0], train_data[1])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (40019, 50, 50, 1)\n",
      "40019 train samples\n",
      "10005 test samples\n",
      "Epoch 00000: val_acc improved from -inf to 0.83948, saving model to /home/u6975/models/Category.best.hdf5\n",
      "Epoch 00001: val_acc improved from 0.83948 to 0.90035, saving model to /home/u6975/models/Category.best.hdf5\n",
      "Epoch 00002: val_acc improved from 0.90035 to 0.90905, saving model to /home/u6975/models/Category.best.hdf5\n",
      "Epoch 00003: val_acc did not improve\n",
      "Epoch 00004: val_acc improved from 0.90905 to 0.91824, saving model to /home/u6975/models/Category.best.hdf5\n",
      "Test score: 0.234385060335\n",
      "Test accuracy: 0.918240879584\n"
     ]
    }
   ],
   "source": [
    "# train it\n",
    "train_model(new_model, x_train, x_test, y_train, y_test, num_classes, epochs, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one(num_classes, modelPath, testImagePath):\n",
    "    test_model = get_model(num_classes)\n",
    "\n",
    "    # load weights\n",
    "    test_model.load_weights(modelPath)\n",
    "    # Compile model (required to make predictions)\n",
    "    test_model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "    # this block is for a example classification\n",
    "    numArr = Image.open(testImagePath)\n",
    "    numArr = numArr.resize((img_rows,img_cols))\n",
    "    numArr = numArr.convert('L')\n",
    "    plt.imshow(numArr)\n",
    "\n",
    "    xArr=[]\n",
    "    xArr.append(numArr)\n",
    "\n",
    "    numArr1 = np.array([np.array(tt).flatten() for tt in xArr])\n",
    "    numArr1 = numArr1.astype(float)\n",
    "    numArr1 /= 255\n",
    "    numArr1 = numArr1.reshape(numArr1.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "    somePredict = test_model.predict_classes(numArr1)\n",
    "    somePredict = somePredict.tolist()\n",
    "    endList = [0] * num_classes\n",
    "    endList[somePredict[0]] = 1 \n",
    "    return endList\n",
    "\n",
    "def test_all(testImagePath):\n",
    "    category = test_one(4, '/home/u6975/models/Category.best.hdf5', testImagePath)\n",
    "    heelHeight = test_one(7, '/home/u6975/models/HeelHeight.best.hdf5', testImagePath)\n",
    "    subCategory = test_one(21, '/home/u6975/models/SubCategory.best.hdf5', testImagePath)\n",
    "    gender = test_one(4, '/home/u6975/models/Gender.best.hdf5', testImagePath)\n",
    "    result = gender + category + heelHeight + subCategory\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['Gender.Men', 'Gender.Women', 'Gender.Boys', 'Gender.Girls', 'Category.Shoes', 'Category.Boots', 'Category.Sandals', 'Category.Slippers', 'HeelHeight.1in...1.3.4in', 'HeelHeight.2in...2.3.4in', 'HeelHeight.Under.1in', 'HeelHeight.Flat', 'HeelHeight.4in...4.3.4in', 'HeelHeight.3in...3.3.4in', 'HeelHeight.5in...over', 'SubCategory.Oxfords', 'SubCategory.Mid.Calf', 'SubCategory.Heel', 'SubCategory.Ankle', 'SubCategory.Boot', 'SubCategory.Loafers', 'SubCategory.Slipper.Flats', 'SubCategory.Boat.Shoes', 'SubCategory.Flat', 'SubCategory.Clogs.and.Mules', 'SubCategory.Flats', 'SubCategory.Sneakers.and.Athletic.Shoes', 'SubCategory.Slipper.Heels', 'SubCategory.Heels', 'SubCategory.Athletic', 'SubCategory.Prewalker', 'SubCategory.Knee.High', 'SubCategory.Prewalker.Boots', 'SubCategory.Crib.Shoes', 'SubCategory.Firstwalker', 'SubCategory.Over.the.Knee']\n",
      "Gender.Men\n",
      "Category.Shoes\n",
      "HeelHeight.Flat\n",
      "SubCategory.Sneakers.and.Athletic.Shoes\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b9810289588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = test_all('testImg1.jpg')\n",
    "print(result)\n",
    "# get all needed headers \n",
    "df = pd.read_csv('meta-data-bin.csv')\n",
    "df1 = df.filter(regex='Category|HeelHeight|Gender')\n",
    "headerList = df1.columns.values.tolist()\n",
    "headerList = headerList[32:] + headerList[0:4] + headerList[25:32] + headerList[4:25]\n",
    "\n",
    "# print the classifications of the image\n",
    "for index, value in enumerate(result):\n",
    "    if value == 1:\n",
    "        print(headerList[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
